{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAT - visualising clustering tendency\n",
    "\n",
    "In lectures 7 and 8 we discussed the VAT algorithm for visualising the clustering tendency of a dataset.   Below is python code for VAT.  You can treat it as a black box (not worrying about the internal coding details) - a function which can be used to execute VAT on an input dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math,random\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def VAT(R):\n",
    "    \"\"\"\n",
    "\n",
    "    VAT algorithm adapted from matlab version:\n",
    "    http://www.ece.mtu.edu/~thavens/code/VAT.m\n",
    "\n",
    "    Args:\n",
    "        R (n*n double): Dissimilarity data input\n",
    "        R (n*D double): vector input (R is converted to sq. Euclidean distance)\n",
    "    Returns:\n",
    "        RV (n*n double): VAT-reordered dissimilarity data\n",
    "        C (n int): Connection indexes of MST in [0,n)\n",
    "        I (n int): Reordered indexes of R, the input data in [0,n)\n",
    "    \"\"\"\n",
    "        \n",
    "    R = np.array(R)\n",
    "    N, M = R.shape\n",
    "    if N != M:\n",
    "        R = squareform(pdist(R))\n",
    "        \n",
    "    J = list(range(0, N))\n",
    "    \n",
    "    y = np.max(R, axis=0)\n",
    "    i = np.argmax(R, axis=0)\n",
    "    j = np.argmax(y)\n",
    "    y = np.max(y)\n",
    "\n",
    "\n",
    "    I = i[j]\n",
    "    del J[I]\n",
    "\n",
    "    y = np.min(R[I,J], axis=0)\n",
    "    j = np.argmin(R[I,J], axis=0)\n",
    "    \n",
    "    I = [I, J[j]]\n",
    "    J = [e for e in J if e != J[j]]\n",
    "    \n",
    "    C = [1,1]\n",
    "    for r in range(2, N-1):   \n",
    "        y = np.min(R[I,:][:,J], axis=0)\n",
    "        i = np.argmin(R[I,:][:,J], axis=0)\n",
    "        j = np.argmin(y)        \n",
    "        y = np.min(y)      \n",
    "        I.extend([J[j]])\n",
    "        J = [e for e in J if e != J[j]]\n",
    "        C.extend([i[j]])\n",
    "    \n",
    "    y = np.min(R[I,:][:,J], axis=0)\n",
    "    i = np.argmin(R[I,:][:,J], axis=0)\n",
    "    \n",
    "    I.extend(J)\n",
    "    C.extend(i)\n",
    "    \n",
    "    RI = list(range(N))\n",
    "    for idx, val in enumerate(I):\n",
    "        RI[val] = idx\n",
    "\n",
    "    RV = R[I,:][:,I]\n",
    "    \n",
    "    return RV.tolist(), C, I\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising iris datset using VAT\n",
    "\n",
    "We will first recreate the visualisations of the iris dataset used in lectures (lecture 7).   Info about the iris dataset is [here](https://en.wikipedia.org/wiki/Iris_flower_data_set).  First a heatmap of the raw iris dataset is displayed.  Secondly a randomly ordered dissimilarity matrix for the objects in iris is shown - notice the lack of structure.   Thirdly the VAT visualisation is produced.  The heatmap function from the seaborn package is employed as a convenient tool for plotting heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "##########################################################\n",
    "#######Read in the datset###############\n",
    "##########################################################\n",
    "iris= pd.read_csv('iris.csv',dtype=None)   ###read in data\n",
    "iris2=iris[[\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\"]] #retain a copy with only these columns\n",
    "\n",
    "####Draw heatmap of raw Iris matrix#######j\n",
    "sns.heatmap(iris2,cmap='viridis',xticklabels=True,yticklabels=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "####Visualise the dissimilarity matrix for Iris using a heatmap (without applying VAT)####\n",
    "iris3=iris2.copy().as_matrix()\n",
    "np.random.shuffle(iris3)   ####randomise the order of rows (objects)\n",
    "sq = squareform(pdist(iris3))   ###commpute the dissimilarity matrix\n",
    "ax=sns.heatmap(sq,cmap='viridis',xticklabels=False,yticklabels=False)\n",
    "ax.set(xlabel='Objects', ylabel='Objects')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#####Apply VAT Algorithm to Iris dataset and visualise using heatmap########\n",
    "RV, C, I = VAT(iris2)\n",
    "x=sns.heatmap(RV,cmap='viridis',xticklabels=False,yticklabels=False)\n",
    "x.set(xlabel='Objects', ylabel='Objects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4a)\n",
    "How many clusters does the VAT visualisation reveal?   Is this what you were expecting given the wikipedia description of this dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal components analysis\n",
    "\n",
    "Principal components analysis can be used for transforming data into a different (lower dimensional) representation.  This is particularly useful for visualisation.\n",
    "\n",
    "The python sci-kit learn package (sklearn) contains functions which can be used for PCA.  Consider the example below of applying PCA on the iris dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA as sklearnPCA##########################################################\n",
    "#######Example of performing PCA on Iris dataset and visualising####################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=2)   #we want just the first two PCs\n",
    "iris_sklearn = sklearn_pca.fit_transform(iris2)\n",
    "print(\"Variance explained by each PC\",sklearn_pca.explained_variance_ratio_)   #print out the amount of variance explained by each PC\n",
    "\n",
    "#set up the colour scheme\n",
    "palette=palette = ['blue','green','red']\n",
    "colors=iris.Name.replace(to_replace=iris.Name.unique(),value=palette).tolist()\n",
    "\n",
    "#plot the objects along the first two principal components, using the colour scheme\n",
    "plt.scatter(iris_sklearn[:,0],iris_sklearn[:,1],s=60,c=colors)   #plot the PC's in 2D\n",
    "plt.xlabel('1st Principal Component', fontsize=28)\n",
    "plt.ylabel('2nd Principal Component', fontsize=28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4b)\n",
    "\n",
    "Based on this visualisation - does it help with your answer to question 4a) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing VAT and PCA\n",
    "\n",
    "You will now practice using the australian crabs dataset from [this file](australian-crabs.csv).   This data describes 200 crabs collected from Fremantle Western Australia.   There are two species of crabs - blue and orange.   Within each species there are male and female.   There are 5 features:\n",
    "\n",
    "FL - frontal lip\n",
    "RW - rear width\n",
    "CL - carapace length\n",
    "CW - carapace width\n",
    "BD - body depth\n",
    "\n",
    "The first four of these are visualised as follows:\n",
    "\n",
    "<img src=\"crabsimage.png\",width=300,height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4c) \n",
    "\n",
    "Adapt the iris example to produce a VAT heatmap of the australian crabs dataset.   How many clusters are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Answer 4c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4d)\n",
    "\n",
    "Using as input the 5 features 'FL','RW','CL','CW','BD' of the crabs, adapt the iris code above and determine the first and second principal components for the australian crabs data.  Print out the variance of each of these components.\n",
    "\n",
    "Plot the crabs in 2D using the first two principal components.  Colour the crabs in violet/yellow/brown/black\n",
    "<ul>\n",
    "<li>violet=blue male crabs\n",
    "<li>yellow= blue female crabs\n",
    "<li>brown=orange male crabs\n",
    "<li>black= orange female crabs\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####4d) answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 4e)\n",
    "Based on your visualisation for the <em>australian crabs</em> dataset, speculate about the \"meaning\" of the first two\n",
    "principal components.  What might each be measuring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4e):\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
