{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "class ClassCounter:\n",
    "    def __init__(self, subject):\n",
    "        #initialize the subject name\n",
    "        self.subject = subject\n",
    "\n",
    "    def prepare(self, class_num):\n",
    "        #initialize the array which is to count how many elements are there in each class\n",
    "        #initialize the array which store the percentage of numbers of each class in the total numbers of instance\n",
    "        self.__classes_count = [0] * class_num\n",
    "        self.__classes_prob = [0] * class_num\n",
    "        \n",
    "    def add(self, class_index):\n",
    "        #count how many elements are there in each class\n",
    "        self.__classes_count[class_index] += 1\n",
    "    \n",
    "    def run(self):\n",
    "        #calculate how many elements are there in total \n",
    "        print(self.__classes_count)\n",
    "        total = sum(self.__classes_count)\n",
    "        #calculate the percentage of numbers of each class in the total numbers of instance\n",
    "        for index, val in enumerate(self.__classes_count):\n",
    "            self.__classes_prob[index] = val/total\n",
    "    \n",
    "    def get(self):\n",
    "        #return the percentage of numbers of each class in the total numbers of instance\n",
    "        return tuple(self.__classes_prob)\n",
    "    \n",
    "    def get_classes_count(self):\n",
    "        #return how many elements are there in each class\n",
    "        return self.__classes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Father class to count the elements of attribute\n",
    "class AttrCounter:\n",
    "    def __init__(self, name):\n",
    "        #store the name of the attribute \n",
    "        self.name = name\n",
    "\n",
    "    def prepare(self, class_num):\n",
    "        #initialize the container to store the elements\n",
    "        return\n",
    "    \n",
    "    def add(self, attr, class_index):\n",
    "        #precess the dataset and instore the elements in to the container that initialized in thre prepare function\n",
    "        return \n",
    "    \n",
    "    def run(self):\n",
    "        #calculate the precentage\n",
    "        return \n",
    "    \n",
    "    def get(self, attr):\n",
    "        #returm the precentage\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#son class to counter the elemnts of nominal attibute\n",
    "class NomCounter(AttrCounter):\n",
    "    __smooth_alpha = 1\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        #store the name of this attribute\n",
    "        super().__init__(name)\n",
    "\n",
    "    def prepare(self, class_num):\n",
    "        #store all the possible values of an attribute in a set\n",
    "        self.__attr_vals = set()\n",
    "        #for each class values, create a dictionary to store the corresponding numbers of this attribute values\n",
    "        self.__attr_count = [defaultdict(int) for i in range(class_num)]\n",
    "        #for each class values, create a dictionary to store the corresponding precentage of this attribute values(the target value)\n",
    "        self.__attr_prob = [defaultdict(float) for i in range(class_num)]\n",
    "    \n",
    "    def add(self, attr, class_index):\n",
    "        #add the attribute values\n",
    "        self.__attr_vals.add(attr)\n",
    "        #add the number of attribute value in corresponding class\n",
    "        self.__attr_count[class_index][attr] += 1\n",
    "    \n",
    "    def run(self):\n",
    "        #number of attribute in the dataset\n",
    "        dimension = len(self.__attr_vals)\n",
    "        #to calculate the precentage of each attribute value precentage in this particular class\n",
    "        for index, attrs in enumerate(self.__attr_count):\n",
    "            total = reduce(lambda x, y: x + y, attrs.values())\n",
    "            for val in self.__attr_vals:\n",
    "                self.__attr_prob[index][val] = self._laplace_smooth(attrs[val], total, dimension)\n",
    "    \n",
    "    def get(self, attr): \n",
    "        #return the precentage\n",
    "        return tuple(prob[attr] for prob in self.__attr_prob)\n",
    "    \n",
    "    #use Laplace smoothing to replace the zero value\n",
    "    def _laplace_smooth(self, num, total, dimension):\n",
    "        return (num+self.__smooth_alpha)/(total+dimension*self.__smooth_alpha)\n",
    "    \n",
    "return_value ='''\n",
    "The example after running this class\n",
    "            self.__attr_val\n",
    "            ---------------\n",
    "            {'high', 'med', 'vhigh', 'low'}\n",
    "            \n",
    "            self.__attr_count\n",
    "            -----------------\n",
    "            [defaultdict(<class 'int'>, {'vhigh': 360, 'high': 324, 'med': 268, 'low': 258}), \n",
    "             defaultdict(<class 'int'>, {'vhigh': 72, 'high': 108, 'med': 115, 'low': 89}), \n",
    "             defaultdict(<class 'int'>, {'med': 23, 'low': 46, 'high': 0, 'vhigh': 0}), \n",
    "             defaultdict(<class 'int'>, {'med': 26, 'low': 39, 'high': 0, 'vhigh': 0})]\n",
    "             \n",
    "            self.__attr_prob\n",
    "            ----------------\n",
    "            [defaultdict(<class 'float'>, {'high': 0.2677100494233937, 'med': 0.2215815485996705, 'vhigh': 0.29736408566721584, 'low': 0.21334431630971992}), \n",
    "             defaultdict(<class 'float'>, {'high': 0.2809278350515464, 'med': 0.29896907216494845, 'vhigh': 0.18814432989690721, 'low': 0.23195876288659795}), \n",
    "             defaultdict(<class 'float'>, {'high': 0.0136986301369863, 'med': 0.3287671232876712, 'vhigh': 0.0136986301369863, 'low': 0.6438356164383562}), \n",
    "             defaultdict(<class 'float'>, {'high': 0.014492753623188406, 'med': 0.391304347826087, 'vhigh': 0.014492753623188406, 'low': 0.5797101449275363})]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#son class to counte the element of the numberical attributes\n",
    "class NumCounter(AttrCounter):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        #store the name of this attribute\n",
    "        super().__init__(name)\n",
    "\n",
    "    def prepare(self, class_num):\n",
    "        self.__all_values = []\n",
    "        #for each class, create the container to store the corresponding attribute values\n",
    "        self.__attr_data = [[] for i in range(class_num)]\n",
    "        #for each class,calculate the mean of this attribute(the target value)\n",
    "        self.__mean = [0] * class_num\n",
    "        #for each class, calculate the deviation of this attribute(the target value)\n",
    "        self.__deviation = [0] * class_num\n",
    "    \n",
    "    def add(self, attr, class_index):\n",
    "        #to store all the values into the container\n",
    "        self.__attr_data[class_index].append(float(attr))\n",
    "        self.__all_values.append(float(attr))\n",
    "    \n",
    "    def run(self):\n",
    "        #use the values that stored in the container to calculate the mean values adn deviation values \n",
    "        for index, data in enumerate(self.__attr_data):\n",
    "            #calculate the mean value\n",
    "            mean = sum(data)/len(data)\n",
    "            #calculate the deviation values\n",
    "            deviation = math.sqrt(sum([(x - mean)**2 for x in data])/(len(data)-1))\n",
    "            #set the mean inside the class\n",
    "            self.__mean[index] = mean\n",
    "            #set the deviation inside the class\n",
    "            self.__deviation[index] = deviation\n",
    "    \n",
    "    def get(self, attr):\n",
    "        #return the normal distribution\n",
    "        return tuple(self._normal_distribution(float(attr), self.__mean[i], self.__deviation[i]) for i in range(len(self.__mean)))\n",
    "    \n",
    "    def _normal_distribution(self, val, mean, deviation):\n",
    "        ###to calculate the normal distribution\n",
    "        return 1/(deviation*math.sqrt(2*math.pi))*np.exp(-((val-mean)/deviation)**2/2) if deviation > 0 else 0\n",
    "    \n",
    "    def draw_histogram(self):\n",
    "        ##################\n",
    "        bin_size = 20#####\n",
    "        ##################\n",
    "        plt.figure()\n",
    "        plt.hist(self.__all_values, bins = bin_size,color = 'steelblue', edgecolor = 'k', label = 'historgram') \n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "        \n",
    "    def draw_box_plot(self):\n",
    "        figure,axes=plt.subplots() #得到画板、轴\n",
    "        axes.boxplot(self.__all_values,patch_artist=True) #描点上色\n",
    "        plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Num2NomCounter(NomCounter):  \n",
    "    def __init__(self, name, bins):\n",
    "        assert(bins >= 2)\n",
    "        super().__init__(name)\n",
    "        self.__bins = bins\n",
    "\n",
    "    def prepare(self, class_num):\n",
    "        self.__split = [0] * (self.__bins-1)\n",
    "        self.__attr_data = []\n",
    "        self.__attr_count = [[0]*self.__bins for i in range(class_num)]\n",
    "        self.__attr_prob = [[0]*self.__bins for i in range(class_num)]\n",
    "    \n",
    "    def add(self, attr, class_index):\n",
    "        self.__attr_data.append((float(attr), class_index))\n",
    "    \n",
    "    def run(self):\n",
    "        self.__attr_data.sort()\n",
    "        gaps = self.__split_integer(len(self.__attr_data),self.__bins)\n",
    "        cur = 0\n",
    "        for i in range(self.__bins-1):\n",
    "            npos = sum(gaps[:i+1])\n",
    "            self.__split[i] = self.__attr_data[npos][0]\n",
    "            for j in range(cur, npos):\n",
    "                self.__attr_count[self.__attr_data[j][1]][i] += 1\n",
    "            cur = npos\n",
    "        for j in range(cur, len(self.__attr_data)):\n",
    "            self.__attr_count[self.__attr_data[j][1]][i+1] += 1           \n",
    "        for index,attrs in enumerate(self.__attr_count):\n",
    "            total = reduce(lambda x, y: x + y, attrs)\n",
    "            for val, num in enumerate(attrs):\n",
    "                self.__attr_prob[index][val] = self._laplace_smooth(num, total, self.__bins)\n",
    "        # print(self.__split)\n",
    "        # print(self.__attr_count)\n",
    "        # print(self.__attr_prob)\n",
    "        # print(\"____________\")\n",
    "    \n",
    "    def get(self, attr):\n",
    "        attr = float(attr)\n",
    "        for i in range(self.__bins):\n",
    "            if i >= len(self.__split) or attr < self.__split[i]:\n",
    "                break\n",
    "        return tuple(prob[i] for prob in self.__attr_prob)\n",
    "    \n",
    "    def __split_integer(self, m, n):\n",
    "        quotient = int(m / n)\n",
    "        remainder = m % n\n",
    "        if remainder > 0:\n",
    "            return [quotient] * (n - remainder) + [quotient + 1] * remainder\n",
    "        if remainder < 0:\n",
    "            return [quotient - 1] * -remainder + [quotient] * (n + remainder)\n",
    "        return [quotient] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nom2NumCounter(NumCounter):\n",
    "    def __init__(self, name, mapper):\n",
    "        super().__init__(name)\n",
    "        self.__mapper = mapper\n",
    "    \n",
    "    def add(self, attr, class_index):\n",
    "        self._attr_data[class_index].append(self.__mapper(attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "#     num_of_class = 0\n",
    "#     num_of_inst = 0\n",
    "#     result = []\n",
    "#     multiclass_matrix=None\n",
    "#     correct_pre = []\n",
    "#     actual_num = []\n",
    "#     predict_num = []\n",
    "    \n",
    "    def __init__(self,result,num_of_class):\n",
    "        #the input(list of tuples, tuple has two value, first one is real class value, second is the predict one)\n",
    "        self.result = result\n",
    "        #number of class\n",
    "        self.num_of_class = num_of_class\n",
    "        #number of instances\n",
    "        self.num_of_inst = len(result)\n",
    "        #generate the muticlass matrix(that mentions in the lecture slide)\n",
    "        self.multiclass_matrix = self.generate_matrix()\n",
    "        #use the multiclass matrix to generte some value that we need to evaluate the model\n",
    "        self.precess_matrix()\n",
    "    \n",
    "    def generate_matrix(self):\n",
    "        matrix = np.zeros((self.num_of_class, self.num_of_class))\n",
    "        for tup in self.result:\n",
    "            matrix[tup[0]][tup[1]]+=1\n",
    "        return matrix\n",
    "    \n",
    "    def precess_matrix(self):\n",
    "        #fill in these array \n",
    "        #the values on the matrix diagonal, how many numbers of instance that the model correctly predict for this particular class\n",
    "        self.correct_pre = [self.multiclass_matrix[i][i] for i in range(self.num_of_class)]\n",
    "        #the actual numbers of instance that each class has in this dataset(TP+FN)\n",
    "        self.actual_num = [self.multiclass_matrix[i].sum() for i in range(self.num_of_class)]\n",
    "        #all numbers of instance that we predict for each class(TP+FP)\n",
    "        self.predict_num = [self.multiclass_matrix[:,i].sum() for i in range(self.num_of_class)]\n",
    "    \n",
    "    \n",
    "    def calculate_accuracy(self):\n",
    "        #calculate the accuracy\n",
    "        accuracy = sum(self.correct_pre)/sum(self.actual_num)\n",
    "        return accuracy\n",
    "    \n",
    "    def calculate_Macro_value(self):   \n",
    "        ###precision###\n",
    "        temp_arr1 = []\n",
    "        #calculate the precision by its formula\n",
    "        for i in range(self.num_of_class):\n",
    "            #if there is any value is 0, then store 0(otherwise, denominator will be zero)\n",
    "            if(self.correct_pre[i]==0 or self.predict_num[i]==0):\n",
    "                temp_arr1.append(0)\n",
    "            else:\n",
    "                this_pre = self.correct_pre[i]/self.predict_num[i]\n",
    "                temp_arr1.append(this_pre)\n",
    "        precision = sum(temp_arr1)/self.num_of_class\n",
    "            \n",
    "        ###recall###\n",
    "        temp_arr2 = []\n",
    "        #calculate the recall by its formula\n",
    "        for i in range(self.num_of_class):\n",
    "            #if there is any value is 0, then store 0(otherwise, denominator will be zero)\n",
    "            if(self.correct_pre[i]==0 or self.actual_num[i]==0):\n",
    "                temp_arr2.append(0)\n",
    "            else:\n",
    "                this_recall = self.correct_pre[i]/self.actual_num[i]\n",
    "                temp_arr2.append(this_recall)\n",
    "        recall = sum(temp_arr2)/self.num_of_class\n",
    "        \n",
    "        return [precision, recall]\n",
    "    \n",
    "    \n",
    "    def calculate_Micro_value(self):\n",
    "        ###precision###\n",
    "        precision = sum(self.correct_pre)/sum(self.predict_num)\n",
    "        ###recall###\n",
    "        recall = sum(self.correct_pre)/sum(self.actual_num)\n",
    "        return [precision, recall]\n",
    "    \n",
    "    def calculate_weight_value(self):\n",
    "        ###precision###\n",
    "        temp_arr1 = []\n",
    "        #calculate the precision by its formula\n",
    "        for i in range(self.num_of_class):\n",
    "            #if there is any value is 0, then store 0(otherwise, denominator will be zero)\n",
    "            if(self.correct_pre[i]==0 or self.predict_num[i]==0):\n",
    "                temp_arr1.append(0)\n",
    "            else:\n",
    "                this_pre = (self.actual_num[i]/self.num_of_inst)*(self.correct_pre[i]/self.predict_num[i])\n",
    "                temp_arr1.append(this_pre)\n",
    "        precision = sum(temp_arr1)     \n",
    "        ###recall###\n",
    "        temp_arr2 = []\n",
    "        #calculate the recall by its formula\n",
    "        for i in range(self.num_of_class):\n",
    "            #if there is any value is 0, then store 0(otherwise, denominator will be zero)\n",
    "            if(self.correct_pre[i]==0 or self.actual_num[i]==0):\n",
    "                temp_arr2.append(0)\n",
    "            else:\n",
    "                this_recall = (self.actual_num[i]/self.num_of_inst)*(self.correct_pre[i]/self.actual_num[i])\n",
    "                temp_arr2.append(this_recall)\n",
    "        recall = sum(temp_arr2)\n",
    "        \n",
    "        return [precision, recall]\n",
    "        \n",
    "        \n",
    "    def draw_heatmap_d(self):\n",
    "        #draw the heatmap with numbers of instance on it\n",
    "        sns.heatmap(self.multiclass_matrix, vmin=0, vmax=len(self.result), annot=True,cmap=\"RdPu_r\", fmt='.20g')\n",
    "        plt.show()\n",
    "        \n",
    "    def draw_heatmap_f(self):\n",
    "        #draw the heatmap with precentage on it\n",
    "        sns.heatmap(self.multiclass_matrix/len(self.result), vmin=0, vmax=1, annot=True,cmap=\"RdPu_r\", fmt='.2g')\n",
    "        plt.show()  \n",
    "        \n",
    "    def draw_bar_chart(self):\n",
    "        #draw the bar chart\n",
    "        #for each class\n",
    "        #show the numbers of predict value, actual value, correctly predict value\n",
    "        names = [\"calss\"+str(i) for i in range(self.num_of_class)]\n",
    "        plt.figure(figsize=(10,6), dpi=80)\n",
    "        x = range(len(names))\n",
    "        \n",
    "        plt.bar(x, self.actual_num, width=0.1)\n",
    "        plt.bar([i + 0.1 for i in x], self.predict_num, width=0.1)\n",
    "        plt.bar([i + 0.2 for i in x], self.correct_pre, width=0.1)\n",
    "\n",
    "        plt.xticks([i + 0.05 for i in x], names)\n",
    "        \n",
    "        plt.xlabel('Class Name', fontsize=14)\n",
    "        plt.ylabel('Number Of Each Class', fontsize=14)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def evaluate(self):\n",
    "        ################################Calculate Accuracy##################################\n",
    "        accuracy = self.calculate_accuracy()\n",
    "        print(self.correct_pre,self.actual_num, self.predict_num)\n",
    "        print(\"accuracy is: %f\" %accuracy)\n",
    "        print(\"error rate is: %f\"%(1-accuracy))\n",
    "\n",
    "        ##macro averaging\n",
    "        precisionMa, recallMa = self.calculate_Macro_value()\n",
    "        print(\"\\n\\n----------------the macro averaging way------------------\")\n",
    "        print(\"Marco averaging precision is: \",precisionMa)\n",
    "        print(\"Marco averaging recall is:\",recallMa)\n",
    "        \n",
    "        #micro averaging\n",
    "        precisionMi, recallMi = self.calculate_Micro_value()\n",
    "        print(\"----------------the micro averaging way------------------\")\n",
    "        print(\"Mirco averaging precision is:\", precisionMi)\n",
    "        print(\"Mirco averaging recall is:\", recallMi)\n",
    "        \n",
    "        #weight averaging\n",
    "        precisionWe, recallWe = self.calculate_weight_value()\n",
    "        print(\"----------------the weight averaging way------------------\")\n",
    "        print(\"weight averaging precision is:\" ,precisionWe)\n",
    "        print(\"weight averaging recall is:\" ,recallWe)\n",
    "        \n",
    "        ###################################Draw Graphs######################################\n",
    "        #self.draw_heatmap_d()\n",
    "        #self.draw_heatmap_f()\n",
    "        #self.draw_bar_chart()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, classes, *counters):\n",
    "        self.num = 10\n",
    "        #convert the class name(string) into the number(start from 0), like class name1 = 0, class name2 = 1, class name3 = 2, etc.\n",
    "        return_value = '''eg. {'unacc': 0, 'acc': 1, 'good': 2, 'vgood': 3}'''\n",
    "        self.__classes = {classname:index for index,classname in enumerate(classes)}\n",
    "        #it is a tuple to store all initialized particular attribute(in the particular type class)\n",
    "        self.__counters = counters\n",
    "        #initialize the filters\n",
    "        self.__filters = ()\n",
    "        #to judge whether we need to delete the first column (some time the first colum is the serial number)\n",
    "        self.__dump_firt_column = False\n",
    "        for index, counter in enumerate(counters):\n",
    "            #if the counter is a class type counter\n",
    "            if isinstance(counter, ClassCounter):\n",
    "                #set the position of the target class column in this Model class \n",
    "                self.__classpos = index\n",
    "            #use the function in the class to prepare the each attribute  (which is initialze all the attributes values container)\n",
    "            counter.prepare(len(classes))\n",
    "            \n",
    "    def set_filters(self, filters):\n",
    "        #set the particular filters\n",
    "        #because different datasets has different punctuation to represent the missing value\n",
    "        #so we need to set the particular filters to particular punctuation\n",
    "        self.__filters = filters\n",
    "        \n",
    "    def set_dump_firt_column(self, enabled):\n",
    "        #set whether we need to delete the first column (some time the first colum is the serial number)\n",
    "        self.__dump_firt_column = enabled\n",
    "            \n",
    "    def preprocess(self, lines):\n",
    "        #we will read the file line by line, so that we gonna preprocess the data line by line\n",
    "        for line in lines:\n",
    "            #split all the data in a line\n",
    "            inputs = line.strip().split(\",\")[1:] if self.__dump_firt_column else line.strip().split(\",\")\n",
    "            #if we successfully read the file lines into the program, continue running this preprocess function\n",
    "            if not inputs or not inputs[0]:\n",
    "                continue\n",
    "                \n",
    "            ###DEALING WITH CLASS VALUE###\n",
    "            #find out the class value of this instance\n",
    "            class_index = self.__classes[inputs[self.__classpos]]\n",
    "            ###DEALING WITH EACH ATTRIBUTE VALUE\n",
    "            #read in all the values and use their particular way to store into their value container \n",
    "            for i, val in enumerate(inputs):\n",
    "                ########!!!!!########\n",
    "                #if there is no missing value, continue store the instance inside the attribute class container, \n",
    "                #otherwise discard this attribute (we choose this way to deal with the missing value which will explain in the written example)\n",
    "                if val not in self.__filters:\n",
    "                    #if this is the value of the target class\n",
    "                    if i == self.__classpos:\n",
    "                        #add value in the ClassCounter\n",
    "                        self.__counters[i].add(class_index)\n",
    "                    else:\n",
    "                        #otherwise add value in their own AttriCounter\n",
    "                        self.__counters[i].add(val, class_index)\n",
    "                \n",
    "    def train(self):\n",
    "        #train the training set by running the function in their class\n",
    "        for counter in self.__counters:\n",
    "            counter.run()\n",
    "\n",
    "    def test(self, lines):\n",
    "        self.res = []\n",
    "        flag = 1\n",
    "        #we still need to read the file line by line, so that we gonna preprocess the test data line by line\n",
    "        for line in lines:\n",
    "            #split all the data in the line\n",
    "            inputs = line.strip().split(\",\")[1:] if self.__dump_firt_column else line.strip().split(\",\")\n",
    "            #if we successfully read the file lines into the program, continue running this preprocess function \n",
    "            if not inputs or not inputs[0]:\n",
    "                continue\n",
    "            \n",
    "            #real target class type of this instance\n",
    "            real = self.__classes[inputs[self.__classpos]]\n",
    "            #all the predict value \n",
    "            predict = []\n",
    "            \n",
    "            for i, val in enumerate(inputs):\n",
    "                #if there is no missing value, continue store the instance inside the attribute class container, \n",
    "                #otherwise discard this attribute (we choose this way to deal with the missing value which will explain in the written example)\n",
    "                if val not in self.__filters:\n",
    "                    #caluculate the presentage that each type that this instance might have\n",
    "                    if i == self.__classpos:\n",
    "                        predict.append(np.log2(np.array(self.__counters[i].get())))\n",
    "                    else:\n",
    "                        predict.append(np.log2(np.array(self.__counters[i].get(val))))\n",
    "            #store the real value and our predict value in a tuple(real value, predict value)\n",
    "            self.res.append((real, np.argmax(reduce(lambda x, y: x*y, predict))))\n",
    "        return self.res\n",
    "    \n",
    "    def train_zero_R_baseline(self):\n",
    "        for counter in self.__counters:\n",
    "            #if the counter is a class type counter\n",
    "            if isinstance(counter, ClassCounter):\n",
    "                #get the each number of times class happened at dataset(which store at the ClassCounter) eg.[3630(class0), 1152(class1), 207(class2), 195(class3)]\n",
    "                self.__class_count = counter.get_classes_count()\n",
    "                #find out the class that happened for most of time\n",
    "                maximum_class = self.__class_count[0]\n",
    "                #return its index(which is the index that represent the class)\n",
    "                self.___majority_class_index = 0\n",
    "                #start to find that class\n",
    "                for i in range(len(self.__class_count)):\n",
    "                    if(self.__class_count[i]>maximum_class):\n",
    "                        maximum_class = self.__class_count[i]\n",
    "                        self.___majority_class_index = i\n",
    "                        \n",
    "    def test_zero_R_baseline(self, lines):\n",
    "        self.res = []\n",
    "        #we still need to read the file line by line, so that we gonna preprocess the test data line by line\n",
    "        for line in lines:\n",
    "            #split all the data in the line\n",
    "            inputs = line.strip().split(\",\")[1:] if self.__dump_firt_column else line.strip().split(\",\")\n",
    "            #if we successfully read the file lines into the program, continue running this preprocess function \n",
    "            if not inputs or not inputs[0]:\n",
    "                continue\n",
    "            #real target class type of this instance\n",
    "            real = self.__classes[inputs[self.__classpos]]\n",
    "            #and predict all the class value of test instance as the class that occur for the most of time\n",
    "            self.res.append((real,self.___majority_class_index))\n",
    "        return self.res\n",
    "    \n",
    "    def evaluate(self):\n",
    "        evaluate_result = Evaluation(self.res, len(self.__classes))\n",
    "        evaluate_result.evaluate()   \n",
    "        return evaluate_result\n",
    "    \n",
    "    def graw_attr_distribution(self):\n",
    "        for counter in self.__counters:\n",
    "            if isinstance(counter, NumCounter):\n",
    "                counter.draw_histogram()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Adult Dataset###\n",
    "####################################################################################################\n",
    "filename = \"datasets/adult.data\"\n",
    "classes = (\"<=50K\" , \">50K\")\n",
    "model = Model(\n",
    "    classes,\n",
    "    NumCounter(\"age\"),\n",
    "    NomCounter(\"workclass\"),\n",
    "    NumCounter(\"fnlwgt\"),\n",
    "    NomCounter(\"education\"),\n",
    "    NomCounter(\"education-num\"),\n",
    "    NomCounter(\"marital-status\"),\n",
    "    NomCounter(\"occupation\"),\n",
    "    NomCounter(\"relationship\"),\n",
    "    NomCounter(\"race\"),\n",
    "    NomCounter(\"sex\"),\n",
    "    NumCounter(\"capital-gain\"),\n",
    "    NumCounter(\"capital-loss\"),\n",
    "    NumCounter(\"hours-per-week\"),\n",
    "    NomCounter(\"native-country\"),\n",
    "    ClassCounter(\"salary\")\n",
    ")\n",
    "model.set_filters((\"?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The runing model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24720, 7841]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianqiu/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in log2\n"
     ]
    }
   ],
   "source": [
    "#weight averaging precision is: 0.871943\n",
    "#weight averaging recall is: 0.715856\n",
    "with open(filename,\"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    model.preprocess(lines)\n",
    "    model.train()\n",
    "    result = model.test(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16849, 7871, 1169, 16850]\n"
     ]
    }
   ],
   "source": [
    "lis = [0, 0, 0, 0]\n",
    "for tuples in result:\n",
    "    if tuples==(0, 0):\n",
    "        lis[0]=lis[0]+1\n",
    "    elif tuples==(0, 1):\n",
    "        lis[1]=lis[1]+1\n",
    "    elif tuples==(1, 0):\n",
    "        lis[2]=lis[2]+1\n",
    "    elif tuples==(1, 1):\n",
    "        lis[3]=lis[0]+1\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation between method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
